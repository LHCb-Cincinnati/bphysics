{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import vector  ## added by mds\n",
    "import awkward as ak\n",
    "import iminuit\n",
    "from iminuit import Minuit\n",
    "from fit_classes import *\n",
    "from utils import *\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the base path to MC files\n",
    "base_path = '/share/lazy/Bu2LambdaPHH/NTuples/MC/'\n",
    "\n",
    "# List all files in the MC directory\n",
    "mc_files = os.listdir(base_path)\n",
    "\n",
    "# Extract unique MC types from the file names. We are assuming that the MC type is the whole part before the last \"_\"\n",
    "mc_types = set([file.rsplit('_', 1)[0] for file in mc_files if file.endswith('.root')])\n",
    "\n",
    "# Display the list of unique MC types to the user\n",
    "print(\"Available MC types:\")\n",
    "for idx, mc_type in enumerate(mc_types, 1):\n",
    "    print(f\"{idx}. {mc_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of MC types\n",
    "mc_types = ['MCBu2L0barPD0bar,KPiPi0', 'MCBu2L0barLambda1520K,PK', \n",
    "            'MCBu2LcbarPPi,Sigma0barPi', 'MCBu2L0barPD0bar,KPi', \n",
    "            'MCBs2L0barPDssm,Dsgamma,KKPi', 'MCB2L0barPKpPim', \n",
    "            'MCBd2L0barPDsm,KKPi', 'MCB2L0barPKmPip', \n",
    "            'MCB2L0PbarKpPip', 'MCBd2LcPiPiP,L0barPi', \n",
    "            'MCBu2LcbarPPi,Sigma0barPiPi0', 'MCBs2L0barPDsm,KKPi',\n",
    "            'MCBu2etacK,PL0barK', 'MCB2L0PbarKpKp', \n",
    "            'MCBd2L0barPDm,KPiPi', 'MCB2L0barPPbarP', \n",
    "            'MCB2L0barPPipPim', 'MCBu2L0barPetaP', \n",
    "            'MCBu2chic0K', 'MCBu2JpsiK,PL0barK', \n",
    "            'MCBu2L0barPPhi,KK', 'MCB2PPbarPPbarPip', \n",
    "            'MCBu2chic2K', 'MCBu2L0barPeta,PiPiX', \n",
    "            'MCBu2chic1K', 'MCB2L0barPJpsi,PPbar', \n",
    "            'MCBd2L0barPDm,KKPi', 'MCB2L0barPPipPip', \n",
    "            'MCBu2LcbarPPi,L0barPiPi0', 'MCBu2Psi2SK', \n",
    "            'MCBd2LcbarL0K,PKPi', 'MCBu2LcbarPPi,L0barPim', \n",
    "            'MCB2L0barPKpKm']\n",
    "\n",
    "\n",
    "# Define available decay trees\n",
    "available_trees = ['B2L0pbarpippim', 'B2L0pbarpippip', 'B2L0pbarKmpip', \n",
    "                   'B2L0pbarKppip', 'B2L0pbarKppim', 'B2L0pbarKpKm', \n",
    "                   'B2L0pbarpp', 'B2L0pbarKpKp']\n",
    "\n",
    "# Show available decay trees\n",
    "print(\"Available decay trees:\")\n",
    "for idx, tree in enumerate(available_trees, 1):\n",
    "    print(f\"{idx}. {tree}\")\n",
    "\n",
    "# Get a physicist input for selected tree\n",
    "tree_idx = int(input(\"Please select the number of your desired decay tree: \")) - 1\n",
    "decay_tree = available_trees[tree_idx]\n",
    "\n",
    "# Define the base path to RD files\n",
    "rd_base_path = '/share/lazy/Bu2LambdaPHH/NTuples/RD/'\n",
    "rd_file_names = ['L0phh_18MU.root', 'L0phh_18MD.root', 'L0phh_17MU.root', \n",
    "                 'L0phh_17MD.root', 'L0phh_16MU.root', 'L0phh_16MD.root', \n",
    "                 'L0phh_15MU.root', 'L0phh_15MD.root']\n",
    "\n",
    "rd_data = [f'{rd_base_path}{file_name}:{decay_tree}/DecayTree' for file_name in rd_file_names]\n",
    "\n",
    "\n",
    "mc_base_path = '/share/lazy/Bu2LambdaPHH/NTuples/MC/'\n",
    "# Display the list of unique MC types to the user\n",
    "print(\"\\nAvailable MC types:\")\n",
    "for idx, mc_type in enumerate(mc_types, 1):\n",
    "    print(f\"{idx}. {mc_type}\")\n",
    "\n",
    "# Load MC data (assuming you have a function called load_mc_data)\n",
    "mc_data = load_mc_data(mc_base_path, mc_types, decay_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Selected decay tree: {decay_tree}\")\n",
    "print(f\"Selected MC type: {mc_type}\")\n",
    "print(f\"Selected RD data: {rd_data}\")\n",
    "print(f\"Selected MC data: {mc_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs_rd = uproot.concatenate(rd_data)\n",
    "print(\"RD Concantenated arrays are ready:\")\n",
    "print(f\"RD Number of events: {len(arrs_rd)}\")\n",
    "\n",
    "/share/lazy/Bu2LambdaPHH/NTuples/MC/MCBs2L0barPDsm,KKPi_15MU.root:B2L0pbarKpKp/DecayTree\n",
    "/share/lazy/Bu2LambdaPHH/NTuples/MC/MCB2L0PbarKpKp_15MU.root:B2L0pbarKpKp/DecayTree≈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for real data\n",
    "h1_P = arrs_rd['h1_P']\n",
    "h1_PT = arrs_rd['h1_PT']\n",
    "h1_PE = arrs_rd['h1_PE']\n",
    "h1_PX = arrs_rd['h1_PX']\n",
    "h1_PY = arrs_rd['h1_PY']\n",
    "h1_PZ = arrs_rd['h1_PZ']\n",
    "h1_ID = arrs_rd['h1_ID']\n",
    "h1_TRACK_Type = arrs_rd['h1_TRACK_Type']\n",
    "h2_P = arrs_rd['h2_P']\n",
    "h2_PT = arrs_rd['h2_PT']\n",
    "h2_PE = arrs_rd['h2_PE']\n",
    "h2_PX = arrs_rd['h2_PX']\n",
    "h2_PY = arrs_rd['h2_PY']\n",
    "h2_PZ = arrs_rd['h2_PZ']\n",
    "h2_ID = arrs_rd['h2_ID']\n",
    "h2_TRACK_Type = arrs_rd['h2_TRACK_Type']\n",
    "p_P = arrs_rd['p_P']\n",
    "p_PT = arrs_rd['p_PT']\n",
    "p_PE = arrs_rd['p_PE']\n",
    "p_PX = arrs_rd['p_PX']\n",
    "p_PY = arrs_rd['p_PY']\n",
    "p_PZ = arrs_rd['p_PZ']\n",
    "p_ID = arrs_rd['p_ID']\n",
    "p_TRACK_Type = arrs_rd['p_TRACK_Type']\n",
    "Lp_P = arrs_rd['Lp_P']\n",
    "Lp_PT = arrs_rd['Lp_PT']\n",
    "Lp_PE = arrs_rd['Lp_PE']\n",
    "Lp_PX = arrs_rd['Lp_PX']\n",
    "Lp_PY = arrs_rd['Lp_PY']\n",
    "Lp_PZ = arrs_rd['Lp_PZ']\n",
    "Lp_ID = arrs_rd['Lp_ID']\n",
    "Lp_TRACK_Type = arrs_rd['Lp_TRACK_Type']\n",
    "Lp_ProbNNp = arrs_rd['Lp_ProbNNp']\n",
    "LL = (3 == Lp_TRACK_Type)\n",
    "DD = (5 == Lp_TRACK_Type)\n",
    "Lpi_P = arrs_rd['Lpi_P']\n",
    "Lpi_PT = arrs_rd['Lpi_PT']\n",
    "Lpi_PE = arrs_rd['Lpi_PE']\n",
    "Lpi_PX = arrs_rd['Lpi_PX']\n",
    "Lpi_PY = arrs_rd['Lpi_PY']\n",
    "Lpi_PZ = arrs_rd['Lpi_PZ']\n",
    "Lpi_ID = arrs_rd['Lpi_ID']\n",
    "Lpi_TRACK_Type = arrs_rd['Lpi_TRACK_Type']\n",
    "Lpi_ProbNNpi = arrs_rd['Lpi_ProbNNpi']\n",
    "L0_P = arrs_rd['L0_P']\n",
    "L0_PT = arrs_rd['L0_PT']\n",
    "L0_PE = arrs_rd['L0_PE']\n",
    "L0_PX = arrs_rd['L0_PX']\n",
    "L0_PY = arrs_rd['L0_PY']\n",
    "L0_PZ = arrs_rd['L0_PZ']\n",
    "L0_ID = arrs_rd['L0_ID']\n",
    "L0_MM = arrs_rd['L0_MM']\n",
    "L0_DOCA12 = arrs_rd['L0_DOCA12']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs_mc = uproot.concatenate(mc_data)\n",
    "print(\"MC Concantenated arrays are ready:\")\n",
    "print(f\"MC Number of events: {len(arrs_mc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for Monte Carlo data\n",
    "h1_P_mc = arrs_mc['h1_P']\n",
    "h1_PT_mc = arrs_mc['h1_PT']\n",
    "h1_PE_mc = arrs_mc['h1_PE']\n",
    "h1_PX_mc = arrs_mc['h1_PX']\n",
    "h1_PY_mc = arrs_mc['h1_PY']\n",
    "h1_PZ_mc = arrs_mc['h1_PZ']\n",
    "h1_ID_mc = arrs_mc['h1_ID']\n",
    "h1_TRACK_Type_mc = arrs_mc['h1_TRACK_Type']\n",
    "h2_P_mc = arrs_mc['h2_P']\n",
    "h2_PT_mc = arrs_mc['h2_PT']\n",
    "h2_PE_mc = arrs_mc['h2_PE']\n",
    "h2_PX_mc = arrs_mc['h2_PX']\n",
    "h2_PY_mc = arrs_mc['h2_PY']\n",
    "h2_PZ_mc = arrs_mc['h2_PZ']\n",
    "h2_ID_mc = arrs_mc['h2_ID']\n",
    "h2_TRACK_Type_mc = arrs_mc['h2_TRACK_Type']\n",
    "p_P_mc = arrs_mc['p_P']\n",
    "p_PT_mc = arrs_mc['p_PT']\n",
    "p_PE_mc = arrs_mc['p_PE']\n",
    "p_PX_mc = arrs_mc['p_PX']\n",
    "p_PY_mc = arrs_mc['p_PY']\n",
    "p_PZ_mc = arrs_mc['p_PZ']\n",
    "p_ID_mc = arrs_mc['p_ID']\n",
    "p_TRACK_Type_mc = arrs_mc['p_TRACK_Type']\n",
    "Lp_P_mc = arrs_mc['Lp_P']\n",
    "Lp_PT_mc = arrs_mc['Lp_PT']\n",
    "Lp_PE_mc = arrs_mc['Lp_PE']\n",
    "Lp_PX_mc = arrs_mc['Lp_PX']\n",
    "Lp_PY_mc = arrs_mc['Lp_PY']\n",
    "Lp_PZ_mc = arrs_mc['Lp_PZ']\n",
    "Lp_ID_mc = arrs_mc['Lp_ID']\n",
    "Lp_TRACK_Type_mc = arrs_mc['Lp_TRACK_Type']\n",
    "Lp_ProbNNp_mc = arrs_mc['Lp_ProbNNp']\n",
    "LL_mc = (3 == Lp_TRACK_Type_mc)\n",
    "DD_mc = (5 == Lp_TRACK_Type_mc)\n",
    "Lpi_P_mc = arrs_mc['Lpi_P']\n",
    "Lpi_PT_mc = arrs_mc['Lpi_PT']\n",
    "Lpi_PE_mc = arrs_mc['Lpi_PE']\n",
    "Lpi_PX_mc = arrs_mc['Lpi_PX']\n",
    "Lpi_PY_mc = arrs_mc['Lpi_PY']\n",
    "Lpi_PZ_mc = arrs_mc['Lpi_PZ']\n",
    "Lpi_ID_mc = arrs_mc['Lpi_ID']\n",
    "Lpi_TRACK_Type_mc = arrs_mc['Lpi_TRACK_Type']\n",
    "Lpi_ProbNNpi_mc = arrs_mc['Lpi_ProbNNpi']\n",
    "L0_P_mc = arrs_mc['L0_P']\n",
    "L0_PT_mc = arrs_mc['L0_PT']\n",
    "L0_PE_mc = arrs_mc['L0_PE']\n",
    "L0_PX_mc = arrs_mc['L0_PX']\n",
    "L0_PY_mc = arrs_mc['L0_PY']\n",
    "L0_PZ_mc = arrs_mc['L0_PZ']\n",
    "L0_ID_mc = arrs_mc['L0_ID']\n",
    "L0_MM_mc = arrs_mc['L0_MM']\n",
    "L0_DOCA12_mc = arrs_mc['L0_DOCA12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lp_ID = ',Lp_ID)\n",
    "if np.any(np.bitwise_or(Lp_ID == 2212, Lp_ID == -2212)):\n",
    "    print('Lp is pi-/+ particles (that should come from Lambda)')\n",
    "else:\n",
    "    print('Lp is not pi-/+ particles (that should come from Lambda)')    \n",
    "print('p_ID = ', p_ID)\n",
    "if np.any(np.bitwise_or(p_ID == 2212, p_ID == -2212)):\n",
    "    print('p is p-/+ particles')\n",
    "else:\n",
    "    print('p is not p-/+ particles. probably something went wrong')    \n",
    "print('h1_ID =', h1_ID)\n",
    "if np.any(np.bitwise_or(h1_ID == 211, h1_ID == -211)):\n",
    "    print('h1 is pi-/+ particles')\n",
    "elif np.any(np.bitwise_or(h1_ID == 321, h1_ID == -321)):\n",
    "    print('h1 is K-/+ particles')\n",
    "elif np.any(np.bitwise_or(h1_ID == 2212, h1_ID == -2212)):\n",
    "    print('h1 is p-/+ particles')    \n",
    "print('h2_ID =', h2_ID)\n",
    "if np.any(np.bitwise_or(h2_ID == 211, h2_ID == -211)):\n",
    "    print('h2 is pi-/+ particles')\n",
    "elif np.any(np.bitwise_or(h2_ID == 321, h2_ID == -321)):\n",
    "    print('h2 is K-/+ particles')\n",
    "elif np.any(np.bitwise_or(h2_ID == 2212, h2_ID == -2212)):\n",
    "    print('h2 is p-/+ particles')        \n",
    "print('Lpi_ID =', Lpi_ID)\n",
    "if np.any(np.bitwise_or(Lpi_ID == 211, Lpi_ID == -211)):\n",
    "    print('Lpi is pi-/+ particles (that should come from Lambda)')\n",
    "else:\n",
    "    print('Lpi is not pi-/+ particles (that should come from Lambda)')    \n",
    "print('L0_ID =', L0_ID)\n",
    "if np.any(np.bitwise_or(L0_ID == 3122, L0_ID == -3122)):\n",
    "    print('L0 is Lambda particles')\n",
    "else:\n",
    "    print('L0 is not Lambda particles. probably something went wrong')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bu_FDCHI2_OWNPV = arrs_rd['Bu_FDCHI2_OWNPV']\n",
    "L0_ENDVERTEX_X = arrs_rd['L0_ENDVERTEX_X'] # The x coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_Y = arrs_rd['L0_ENDVERTEX_Y'] # The y coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_Z = arrs_rd['L0_ENDVERTEX_Z'] # The z coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_XERR = arrs_rd['L0_ENDVERTEX_XERR'] # The error on the x coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_YERR = arrs_rd['L0_ENDVERTEX_YERR'] # The error on the y coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_ZERR = arrs_rd['L0_ENDVERTEX_ZERR'] # The error on the z coordinate of the L0 decay vertex\n",
    "L0_OWNPV_Z = arrs_rd['L0_OWNPV_Z'] # The z coordinate of the L0 production vertex\n",
    "L0_OWNPV_ZERR = arrs_rd['L0_OWNPV_ZERR'] # The error on the z coordinate of the L0 production vertex\n",
    "\n",
    "L0_FD_OWNPV = arrs_rd['L0_FD_OWNPV'] # The flight distance of the L0 decay vertex from the L0 production vertex\n",
    "L0_FDCHI2_OWNPV = arrs_rd['L0_FDCHI2_OWNPV'] # The flight distance of the L0 decay vertex from the L0 production vertex, normalised by its uncertainty\n",
    "Bu_ENDVERTEX_X = arrs_rd['Bu_ENDVERTEX_X'] # The x coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_Y = arrs_rd['Bu_ENDVERTEX_Y'] # The y coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_Z = arrs_rd['Bu_ENDVERTEX_Z'] # The z coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_XERR = arrs_rd['Bu_ENDVERTEX_XERR'] # The error on the x coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_YERR = arrs_rd['Bu_ENDVERTEX_YERR'] # The error on the y coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_ZERR = arrs_rd['Bu_ENDVERTEX_ZERR'] # The error on the z coordinate of the Bu decay vertex\n",
    "Bu_IPCHI2_OWNPV = arrs_rd['Bu_IPCHI2_OWNPV'] # The chi-square of the impact parameter (the distance of closest approach of the particle track to the primary vertex)\n",
    "Bu_MM = arrs_rd['Bu_MM'] # The invariant mass of the Bu candidate\n",
    "\n",
    "Bu_DOCA12 = arrs_rd['Bu_DOCA12'] # The distance of closest approach between the two daughters of the Bu candidate\n",
    "Delta_Z = L0_ENDVERTEX_Z - Bu_ENDVERTEX_Z # The difference in z coordinates between the L0 and Bu decay vertices\n",
    "Delta_X = L0_ENDVERTEX_X - Bu_ENDVERTEX_X # The difference in x coordinates between the L0 and Bu decay vertices\n",
    "Delta_Y = L0_ENDVERTEX_Y - Bu_ENDVERTEX_Y # The difference in y coordinates between the L0 and Bu decay vertices\n",
    "Delta_X_ERR = np.sqrt(np.square(Bu_ENDVERTEX_XERR)+np.square(L0_ENDVERTEX_XERR)) # The error on the difference in x coordinates between the L0 and Bu decay vertices\n",
    "Delta_Y_ERR = np.sqrt(np.square(Bu_ENDVERTEX_YERR)+np.square(L0_ENDVERTEX_YERR)) # The error on the difference in y coordinates between the L0 and Bu decay vertices\n",
    "Delta_Z_ERR = np.sqrt(np.square(Bu_ENDVERTEX_ZERR)+np.square(L0_ENDVERTEX_ZERR)) # The error on the difference in z coordinates between the L0 and Bu decay vertices\n",
    "Delta_X_ERR_sq = np.square(Delta_X_ERR)\n",
    "Delta_Y_ERR_sq = np.square(Delta_Y_ERR)\n",
    "Delta_Z_ERR_sq = np.square(Delta_Z_ERR)\n",
    "\n",
    "delta_x = np.divide(Delta_X,Delta_X_ERR) # The difference in x coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "delta_y = np.divide(Delta_Y,Delta_Y_ERR) # The difference in y coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "delta_z = np.divide(Delta_Z,Delta_Z_ERR) # The difference in z coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "L0_FD_CHISQ = np.square(delta_x) + np.square(delta_y) + np.square(delta_z) # The flight distance of the L0 decay vertex from the L0 production vertex, normalised by its uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bu_FDCHI2_OWNPV = arrs_rd['Bu_FDCHI2_OWNPV']\n",
    "L0_ENDVERTEX_X = arrs_rd['L0_ENDVERTEX_X'] # The x coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_Y = arrs_rd['L0_ENDVERTEX_Y'] # The y coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_Z = arrs_rd['L0_ENDVERTEX_Z'] # The z coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_XERR = arrs_rd['L0_ENDVERTEX_XERR'] # The error on the x coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_YERR = arrs_rd['L0_ENDVERTEX_YERR'] # The error on the y coordinate of the L0 decay vertex\n",
    "L0_ENDVERTEX_ZERR = arrs_rd['L0_ENDVERTEX_ZERR'] # The error on the z coordinate of the L0 decay vertex\n",
    "L0_OWNPV_Z = arrs_rd['L0_OWNPV_Z'] # The z coordinate of the L0 production vertex\n",
    "L0_OWNPV_ZERR = arrs_rd['L0_OWNPV_ZERR'] # The error on the z coordinate of the L0 production vertex\n",
    "\n",
    "L0_FD_OWNPV = arrs_rd['L0_FD_OWNPV'] # The flight distance of the L0 decay vertex from the L0 production vertex\n",
    "L0_FDCHI2_OWNPV = arrs_rd['L0_FDCHI2_OWNPV'] # The flight distance of the L0 decay vertex from the L0 production vertex, normalised by its uncertainty\n",
    "Bu_ENDVERTEX_X = arrs_rd['Bu_ENDVERTEX_X'] # The x coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_Y = arrs_rd['Bu_ENDVERTEX_Y'] # The y coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_Z = arrs_rd['Bu_ENDVERTEX_Z'] # The z coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_XERR = arrs_rd['Bu_ENDVERTEX_XERR'] # The error on the x coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_YERR = arrs_rd['Bu_ENDVERTEX_YERR'] # The error on the y coordinate of the Bu decay vertex\n",
    "Bu_ENDVERTEX_ZERR = arrs_rd['Bu_ENDVERTEX_ZERR'] # The error on the z coordinate of the Bu decay vertex\n",
    "Bu_IPCHI2_OWNPV = arrs_rd['Bu_IPCHI2_OWNPV'] # The chi-square of the impact parameter (the distance of closest approach of the particle track to the primary vertex)\n",
    "Bu_MM = arrs_rd['Bu_MM'] # The invariant mass of the Bu candidate\n",
    "\n",
    "Bu_DOCA12 = arrs_rd['Bu_DOCA12'] # The distance of closest approach between the two daughters of the Bu candidate\n",
    "Delta_Z = L0_ENDVERTEX_Z - Bu_ENDVERTEX_Z # The difference in z coordinates between the L0 and Bu decay vertices\n",
    "Delta_X = L0_ENDVERTEX_X - Bu_ENDVERTEX_X # The difference in x coordinates between the L0 and Bu decay vertices\n",
    "Delta_Y = L0_ENDVERTEX_Y - Bu_ENDVERTEX_Y # The difference in y coordinates between the L0 and Bu decay vertices\n",
    "Delta_X_ERR = np.sqrt(np.square(Bu_ENDVERTEX_XERR)+np.square(L0_ENDVERTEX_XERR)) # The error on the difference in x coordinates between the L0 and Bu decay vertices\n",
    "Delta_Y_ERR = np.sqrt(np.square(Bu_ENDVERTEX_YERR)+np.square(L0_ENDVERTEX_YERR)) # The error on the difference in y coordinates between the L0 and Bu decay vertices\n",
    "Delta_Z_ERR = np.sqrt(np.square(Bu_ENDVERTEX_ZERR)+np.square(L0_ENDVERTEX_ZERR)) # The error on the difference in z coordinates between the L0 and Bu decay vertices\n",
    "Delta_X_ERR_sq = np.square(Delta_X_ERR)\n",
    "Delta_Y_ERR_sq = np.square(Delta_Y_ERR)\n",
    "Delta_Z_ERR_sq = np.square(Delta_Z_ERR)\n",
    "\n",
    "delta_x = np.divide(Delta_X,Delta_X_ERR) # The difference in x coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "delta_y = np.divide(Delta_Y,Delta_Y_ERR) # The difference in y coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "delta_z = np.divide(Delta_Z,Delta_Z_ERR) # The difference in z coordinates between the L0 and Bu decay vertices, normalised by its uncertainty\n",
    "L0_FD_CHISQ = np.square(delta_x) + np.square(delta_y) + np.square(delta_z) # The flight distance of the L0 decay vertex from the L0 production vertex, normalised by its uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bu_FDCHI2_OWNPV_mc = arrs_mc['Bu_FDCHI2_OWNPV']\n",
    "L0_ENDVERTEX_X_mc = arrs_mc['L0_ENDVERTEX_X']\n",
    "L0_ENDVERTEX_Y_mc = arrs_mc['L0_ENDVERTEX_Y']\n",
    "L0_ENDVERTEX_Z_mc = arrs_mc['L0_ENDVERTEX_Z']\n",
    "L0_ENDVERTEX_XERR_mc = arrs_mc['L0_ENDVERTEX_XERR']\n",
    "L0_ENDVERTEX_YERR_mc = arrs_mc['L0_ENDVERTEX_YERR']\n",
    "L0_ENDVERTEX_ZERR_mc = arrs_mc['L0_ENDVERTEX_ZERR']\n",
    "L0_OWNPV_Z_mc = arrs_mc['L0_OWNPV_Z']\n",
    "L0_OWNPV_ZERR_mc = arrs_mc['L0_OWNPV_ZERR']\n",
    "L0_FD_OWNPV_mc = arrs_mc['L0_FD_OWNPV']\n",
    "L0_FDCHI2_OWNPV_mc = arrs_mc['L0_FDCHI2_OWNPV']\n",
    "Bu_ENDVERTEX_X_mc = arrs_mc['Bu_ENDVERTEX_X']\n",
    "Bu_ENDVERTEX_Y_mc = arrs_mc['Bu_ENDVERTEX_Y']\n",
    "Bu_ENDVERTEX_Z_mc = arrs_mc['Bu_ENDVERTEX_Z']\n",
    "Bu_ENDVERTEX_XERR_mc = arrs_mc['Bu_ENDVERTEX_XERR']\n",
    "Bu_ENDVERTEX_YERR_mc = arrs_mc['Bu_ENDVERTEX_YERR']\n",
    "Bu_ENDVERTEX_ZERR_mc = arrs_mc['Bu_ENDVERTEX_ZERR']\n",
    "Bu_IPCHI2_OWNPV_mc = arrs_mc['Bu_IPCHI2_OWNPV']\n",
    "Bu_MM_mc = arrs_mc['Bu_MM']\n",
    "Bu_DOCA12_mc = arrs_mc['Bu_DOCA12']\n",
    "\n",
    "Delta_Z_mc = L0_ENDVERTEX_Z_mc - Bu_ENDVERTEX_Z_mc\n",
    "Delta_X_mc = L0_ENDVERTEX_X_mc - Bu_ENDVERTEX_X_mc\n",
    "Delta_Y_mc = L0_ENDVERTEX_Y_mc - Bu_ENDVERTEX_Y_mc\n",
    "Delta_X_ERR_mc = np.sqrt(np.square(Bu_ENDVERTEX_XERR_mc)+np.square(L0_ENDVERTEX_XERR_mc))\n",
    "Delta_Y_ERR_mc = np.sqrt(np.square(Bu_ENDVERTEX_YERR_mc)+np.square(L0_ENDVERTEX_YERR_mc))\n",
    "Delta_Z_ERR_mc = np.sqrt(np.square(Bu_ENDVERTEX_ZERR_mc)+np.square(L0_ENDVERTEX_ZERR_mc))\n",
    "Delta_X_ERR_sq_mc = np.square(Delta_X_ERR_mc)\n",
    "Delta_Y_ERR_sq_mc = np.square(Delta_Y_ERR_mc)\n",
    "Delta_Z_ERR_sq_mc = np.square(Delta_Z_ERR_mc)\n",
    "\n",
    "delta_x_mc = np.divide(Delta_X_mc,Delta_X_ERR_mc)\n",
    "delta_y_mc = np.divide(Delta_Y_mc,Delta_Y_ERR_mc)\n",
    "delta_z_mc = np.divide(Delta_Z_mc,Delta_Z_ERR_mc)\n",
    "L0_FD_CHISQ_mc = np.square(delta_x_mc) + np.square(delta_y_mc) + np.square(delta_z_mc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cuts and definitions\n",
    "\n",
    "h1_probNNk = arrs_rd['h1_MC15TuneV1_ProbNNk']\n",
    "h2_probNNk = arrs_rd['h2_MC15TuneV1_ProbNNk']\n",
    "p_ProbNNp  = arrs_rd['p_MC15TuneV1_ProbNNp']\n",
    "\n",
    "\n",
    "good_Delta_Z = Delta_Z>0.\n",
    "good_Lambda_chisq_9 = L0_FD_CHISQ>9.\n",
    "good_Lambda_sep_9 =  good_Delta_Z & good_Lambda_chisq_9\n",
    "bad_Delta_Z = Delta_Z<0.\n",
    "bad_Lambda_chisq_9  = L0_FD_CHISQ<9.\n",
    "bad_Lambda_sep_9 =  bad_Delta_Z | bad_Lambda_chisq_9\n",
    "good_Delta_Z = Delta_Z>0.\n",
    "good_Lambda_chisq_100  = L0_FD_CHISQ>100.\n",
    "good_Lambda_sep_100 =  good_Delta_Z & good_Lambda_chisq_100\n",
    "\n",
    "\n",
    "\n",
    "ProbNNp_0p1_0p2 = (Lp_ProbNNp>0.1) & (Lp_ProbNNp<0.2)\n",
    "prodProbKK = np.multiply(h1_probNNk,h2_probNNk)\n",
    "\n",
    "B_region = (Bu_MM>5255.) & (Bu_MM<5305.)\n",
    "prodProbNNx = np.multiply(p_ProbNNp,prodProbKK)\n",
    "\n",
    "good_LambdaLL   = (Lp_ProbNNp>0.2) & (L0_MM>1111) & (L0_MM<1121) & good_Delta_Z & good_Lambda_chisq_100 & LL\n",
    "good_LambdaDD   = (Lp_ProbNNp>0.2) & (L0_MM>1111) & (L0_MM<1121) & DD\n",
    "good_Lambda     = good_LambdaLL | good_LambdaDD\n",
    "good_prompt     = (Lp_ProbNNp>0.2) & (L0_FD_CHISQ<9) & LL\n",
    "better_Lambda   = good_Lambda & (Bu_IPCHI2_OWNPV<6) \n",
    "better_LambdaLL = good_LambdaLL & (Bu_IPCHI2_OWNPV<6)\n",
    "better_LambdaDD = good_LambdaDD & (Bu_IPCHI2_OWNPV<6)\n",
    "\n",
    "temp_cut = good_Delta_Z & good_Lambda_chisq_100 & (Lp_ProbNNp>0.2)\n",
    "temp_cutLL = temp_cut & LL\n",
    "temp_cutDD = temp_cut & DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the B+ mass for both MC and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6)) # Creates 2 subplots side by side\n",
    "\n",
    "# Compute and plot real data histogram\n",
    "nC, bins, _ = axs[0].hist(Bu_MM, bins=75, range=(4700,6200)) # Bu_MM should be calculated from real data\n",
    "axs[0].set_title('Bu_MM Real Data')\n",
    "axs[0].set_xlabel(r'Bu_MM [MeV]')\n",
    "axs[0].set_ylabel('entries per 10 MeV')\n",
    "axs[0].axis([4700,6200.,0,1.15*max(nC)])\n",
    "axs[0].grid(True)\n",
    "axs[0].vlines(5255., 0., 0.6*max(nC), colors='red')\n",
    "axs[0].vlines(5305., 0., 0.6*max(nC), colors='red')\n",
    "\n",
    "# Compute and plot Monte Carlo histogram\n",
    "nC_mc, bins_mc, _ = axs[1].hist(Bu_MM_mc, bins=75, range=(4700,6200)) # Bu_MM_mc should be calculated from MC data\n",
    "axs[1].set_title('Bu_MM Monte Carlo')\n",
    "axs[1].set_xlabel(r'Bu_MM [MeV]')\n",
    "axs[1].set_ylabel('entries per 10 MeV')\n",
    "axs[1].axis([4700,6200.,0,1.15*max(nC_mc)])\n",
    "axs[1].grid(True)\n",
    "axs[1].vlines(5255., 0., 0.6*max(nC_mc), colors='red')\n",
    "axs[1].vlines(5305., 0., 0.6*max(nC_mc), colors='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for Lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6)) # Creates 2 subplots side by side\n",
    "\n",
    "# Compute and plot real data histogram\n",
    "nC, bins, _ = axs[0].hist(L0_MM, bins=30, range=(1100, 1130)) # L0_MM should be calculated from real data\n",
    "axs[0].set_title('Bu_MM Real Data')\n",
    "axs[0].set_xlabel(r'L0_MM_MM [MeV]')\n",
    "axs[0].set_ylabel('entries per 10 MeV')\n",
    "axs[0].axis([1100, 1130.,0,1.15*max(nC)])\n",
    "axs[0].grid(True)\n",
    "axs[0].vlines(1114., 0., 0.6*max(nC), colors='red')\n",
    "axs[0].vlines(1118., 0., 0.6*max(nC), colors='red')\n",
    "\n",
    "# Compute and plot Monte Carlo histogram\n",
    "nC_mc, bins_mc, _ = axs[1].hist(L0_MM_mc, bins=30, range=(1100, 1130)) # L0_MM_mc should be calculated from MC data\n",
    "axs[1].set_title('L0_MM Monte Carlo')\n",
    "axs[1].set_xlabel(r'L0_MM [MeV]')\n",
    "axs[1].set_ylabel('entries per 1 MeV')\n",
    "axs[1].axis([1100, 1130.,0,1.15*max(nC_mc)])\n",
    "axs[1].grid(True)\n",
    "axs[0].vlines(1114., 0., 0.6*max(nC_mc), colors='red')\n",
    "axs[0].vlines(1118., 0., 0.6*max(nC_mc), colors='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B Fitting\n",
    "\n",
    "\n",
    "First lets try to get a good B+ sample. we will try the following cuts\n",
    "\n",
    "- p_ProbNNp\n",
    "- good_Lambda\n",
    "- prodProbKK > 0.2\n",
    "- B_region\n",
    "- Bu_IPCHI2_OWNPV < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_b = good_Lambda & (prodProbKK > 0.4) & (p_ProbNNp > 0.5) \n",
    "good_cand = good_Lambda & (prodProbKK > 0.4) & (p_ProbNNp > 0.5) & (Bu_MM > 5200) & (Bu_MM < 5400)\n",
    "better_b = good_b & (Bu_IPCHI2_OWNPV < 10)\n",
    "\n",
    "\n",
    "\n",
    "# add mass cut that Bu_MM is between 5200 and 5400\n",
    "good_b_mass = Bu_MM[better_b]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now lets plot the Bu_Mass for `good_b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(Bu_MM, bins=60, range=(5200, 5400), facecolor='r', edgecolor='r', alpha=0.2, label='No cuts')\n",
    "plt.hist(Bu_MM[better_b], bins=60, range=(5200, 5400), facecolor='b', edgecolor='b', alpha=0.5, label='better_b')\n",
    "plt.hist(Bu_MM[good_b], bins=60, range=(5200, 5400), facecolor='brown', edgecolor='brown', alpha=0.5, label='good_b')\n",
    "plt.hist(Bu_MM[good_cand], bins=60, range=(5200, 5400), facecolor='g', edgecolor='g', alpha=0.2, label='good_cand')\n",
    "\n",
    "plt.xlabel('Bu_MM')\n",
    "plt.ylabel('Entries per 5 MeV')\n",
    "plt.title('Bu_MM with different cuts')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected between good_b and better_b\n",
    "rejected_good_better = np.not_equal(good_b, better_b)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(Bu_MM[good_b], bins=50, range=(5200, 5400), facecolor='r', edgecolor='r', alpha=0.5, label='good_b')\n",
    "plt.hist(Bu_MM[better_b], bins=50, range=(5200, 5400), facecolor='b', edgecolor='b', alpha=0.5, label='better_b')\n",
    "plt.hist(Bu_MM[rejected_good_better], bins=50, range=(5200, 5400), facecolor='g', edgecolor='g', alpha=1, label='difference')\n",
    "plt.xlabel('Bu_MM')\n",
    "plt.ylabel('Entries per 4 MeV')\n",
    "plt.title('Bu_MM with different cuts')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of events passing 'good_b' selection: {len(Bu_MM[good_b])}\")\n",
    "print(f\"Number of events passing 'better_b' selection: {len(Bu_MM[better_b])}\")\n",
    "print(f\"Number of events passing 'good_cand' selection: {len(Bu_MM[good_cand])}\")\n",
    "print(f\"Total number of events: {len(Bu_MM)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the B mass for both MC and Data (with different cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the figure and subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot the MC data\n",
    "axs[0, 0].hist(Bu_MM_mc, bins=60, range=(5220, 5340))\n",
    "axs[0, 0].set_title(\"MC Data\")\n",
    "\n",
    "# Plot the real data without cuts\n",
    "axs[0, 1].hist(Bu_MM, bins=60, range=(5220, 5340))\n",
    "axs[0, 1].set_title(\"Real Data (No Cuts)\")\n",
    "\n",
    "# Plot the real data with good_cand\n",
    "axs[1, 0].hist(Bu_MM[good_cand], bins=60, range=(5220, 5340))\n",
    "axs[1, 0].set_title(\"Real Data (good_cand)\")\n",
    "\n",
    "# Plot the real data with better_b\n",
    "axs[1, 1].hist(Bu_MM[better_b], bins=60, range=(5220, 5340))\n",
    "axs[1, 1].set_title(\"Real Data (better_b)\")\n",
    "\n",
    "# Add a title and axis labels\n",
    "fig.suptitle(\"B Mass Plots\")\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"B Mass [MeV]\", ylabel=\"Events per 2 MeV\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how much we removed by applying the cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot the Bu_Mass for good_b\n",
    "\n",
    "rejected = np.logical_not(good_cand)\n",
    "plt.figure()\n",
    "plt.hist(Bu_MM, bins=50, range=(5200, 5400), facecolor='r', edgecolor='r', alpha=0.2, label='All')\n",
    "plt.hist(Bu_MM[rejected], bins=50, range=(5200, 5400), facecolor='g', edgecolor='g', alpha=0.75, label='Rejected')\n",
    "plt.hist(Bu_MM[better_b], bins=50, range=(5200, 5400), facecolor='b', edgecolor='b', alpha=0.75, label='Accepted')\n",
    "plt.xlabel('Bu_MM')\n",
    "plt.ylabel('Entries per 20 MeV')\n",
    "plt.title('Bu_MM with better_b')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the event weight for each event\n",
    "event_weight = np.ones_like(Bu_MM)\n",
    "\n",
    "# Calculate the signal efficiency weight for each event\n",
    "signal_efficiency_weight = np.ones_like(Bu_MM)\n",
    "\n",
    "# Calculate the signal weight for each event\n",
    "signal_weights = event_weight * signal_efficiency_weight\n",
    "\n",
    "# Calculate the total number of signal events\n",
    "total_signal_events = np.sum(signal_weights)\n",
    "\n",
    "# Calculate the number of signal events passing the 'good_cand' cut\n",
    "good_cand_signal_events = np.sum(signal_weights[good_cand])\n",
    "\n",
    "# Calculate the number of signal events passing the 'better_b' cut\n",
    "better_b_signal_events = np.sum(signal_weights[better_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebands \n",
    "\n",
    "The following code defines three regions of the B meson mass distribution: a signal region and two sideband regions. The signal region is where the signal of new physics is expected to appear, while the sideband regions are used to estimate the background from known physics processes.\n",
    "\n",
    "We then defines a list of cuts, which are criteria used to select events that are more likely to contain a B meson. The cuts are applied to the signal and sideband regions, and the number of signal and background events passing the cuts are counted. The signal efficiency is then calculated as the fraction of signal events passing the cuts in the signal region, while the background rejection is calculated as the fraction of background events passing the cuts in the sideband regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficiency_rejection(cut, signal_region, left_sideband_region, right_sideband_region):\n",
    "    # Apply the cut and calculate the number of signal and background events passing the cut in the signal and sideband regions\n",
    "    cut_array = eval(cut)\n",
    "    signal_passing_cut_signal = np.sum(signal_weights[(B_mass > signal_region[0]) & (B_mass < signal_region[1]) & cut_array])\n",
    "    background_passing_cut_signal = np.sum(signal_weights[(B_mass > signal_region[0]) & (B_mass < signal_region[1]) & ~cut_array])\n",
    "    signal_passing_cut_left_sideband = np.sum(signal_weights[(B_mass > left_sideband_region[0]) & (B_mass < left_sideband_region[1]) & cut_array])\n",
    "    background_passing_cut_left_sideband = np.sum(signal_weights[(B_mass > left_sideband_region[0]) & (B_mass < left_sideband_region[1]) & ~cut_array])\n",
    "    signal_passing_cut_right_sideband = np.sum(signal_weights[(B_mass > right_sideband_region[0]) & (B_mass < right_sideband_region[1]) & cut_array])\n",
    "    background_passing_cut_right_sideband = np.sum(signal_weights[(B_mass > right_sideband_region[0]) & (B_mass < right_sideband_region[1]) & ~cut_array])\n",
    "\n",
    "    # Calculate the signal efficiency and background rejection\n",
    "    total_signal_events = np.sum(signal_weights[(B_mass > signal_region[0]) & (B_mass < signal_region[1])])\n",
    "    total_background_events = (np.sum(signal_weights[(B_mass > left_sideband_region[0]) & (B_mass < left_sideband_region[1])]) +\n",
    "                               np.sum(signal_weights[(B_mass > right_sideband_region[0]) & (B_mass < right_sideband_region[1])]))\n",
    "    signal_efficiency = signal_passing_cut_signal / total_signal_events\n",
    "    background_rejection = (background_passing_cut_left_sideband + background_passing_cut_right_sideband) / total_background_events\n",
    "\n",
    "    return cut, signal_efficiency, background_rejection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the signal and sideband regions\n",
    "'''\n",
    "signal_region = (5278, 5280)\n",
    "left_sideband_region = (5275, 5278)\n",
    "right_sideband_region = (5280, 5285)\n",
    "'''\n",
    "\n",
    "# Define the signal and sideband regions\n",
    "B_mass = Bu_MM\n",
    "signal_region = (5255, 5305)\n",
    "left_sideband_region = (5100, 5200)\n",
    "right_sideband_region = (5355, 5455)\n",
    "\n",
    "# Define the list of cuts\n",
    "cuts = ['good_cand', 'good_b', 'better_b']\n",
    "\n",
    "\n",
    "# Loop over each cut and print the signal efficiency and background rejection\n",
    "for cut in cuts:\n",
    "    cut, signal_efficiency, background_rejection = calculate_efficiency_rejection(cut, signal_region, left_sideband_region, right_sideband_region)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Cut: {cut}\")\n",
    "    print(f\"Signal efficiency: {signal_efficiency:.4f}\")\n",
    "    print(f\"Background rejection: {background_rejection:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to fit this plot. lets first try doublegaussian plus expoentnial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_name = \"_B\"\n",
    "\n",
    "# Define a dictionary to store your variables\n",
    "variables = {\n",
    "    \"nC\": None,\n",
    "    \"bins\": None,\n",
    "    \"patches\": None,\n",
    "    \"init_pars\": None,\n",
    "    \"minuit_limits\": None,\n",
    "    \"fit_model\": None,\n",
    "    \"fit_result\": None,\n",
    "    \"fig\": None,\n",
    "    \"ax\": None,\n",
    "}\n",
    "\n",
    "# Use the class:\n",
    "variables[\"nC\" + root_name], variables[\"bins\" + root_name], variables[\"patches\" + root_name] = plt.hist(good_b_mass, bins=40, range=(5240,5320))\n",
    "plt.close()\n",
    "\n",
    "# DoubleGaussian_plus_Exp [n_s, f, n_b, mu1, mu2, sigma1, sigma2, A, b] \n",
    "variables[\"init_pars\" + root_name] = [2107.342774243925, 0.30675368786004314, 20.31478818173544, 5301.154728419139, 5284.482097051684, 47.16245660975994, 49.1673569774403, -0.009140287076873227, -0.06243005820615455]\n",
    "variables[\"minuit_limits\" + root_name] = {\n",
    "    \"f\": (0.0001, 0.9999),\n",
    "}\n",
    "\n",
    "variables[\"fit_model\" + root_name] = DoubleGaussian_plus_Exp(variables[\"bins\" + root_name], variables[\"nC\" + root_name], variables[\"minuit_limits\" + root_name])\n",
    "\n",
    "variables[\"fit_result\" + root_name] = variables[\"fit_model\" + root_name].fit(variables[\"init_pars\" + root_name])\n",
    "\n",
    "# Print the fitted parameters\n",
    "print(\"Fitted parameters:\", variables[\"fit_result\" + root_name].values)\n",
    "variables[\"fit_result\" + root_name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the fit plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_name = \"_B\"\n",
    "\n",
    "variables[\"fig\" + root_name], variables[\"ax\" + root_name] = variables[\"fit_model\" + root_name].plot(variables[\"fit_result\" + root_name], variables[\"bins\" + root_name], variables[\"nC\" + root_name], title='Bu_MM with better_b ', xlabel='Bu Mass', ylabel='Entries per 0.5 MeV', vlines=[], show_plot=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that I need some random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_name = \"_B\"\n",
    "\n",
    "# Define a dictionary to store your variables\n",
    "variables = {\n",
    "    \"nC\": None,\n",
    "    \"bins\": None,\n",
    "    \"patches\": None,\n",
    "    \"param_ranges\": None,\n",
    "    \"random_search\": None,\n",
    "    \"best_score\": None,\n",
    "    \"best_params\": None,\n",
    "    \"best_fit\": None,\n",
    "    \"best_fit_m\": None,\n",
    "    \"parsed_output\": None,\n",
    "}\n",
    "\n",
    "# Use the class:\n",
    "variables[\"nC\" + root_name], variables[\"bins\" + root_name], variables[\"patches\" + root_name] = plt.hist(good_b_mass, bins=60, range=(1100,1130))\n",
    "plt.close()\n",
    "\n",
    "variables[\"param_ranges\" + root_name] = {\n",
    "    \"n_s\": (1000, 10000),\n",
    "    \"f\": (0.001, 0.999),\n",
    "    \"n_b\": (10, 100),\n",
    "    \"mu1\": (5240,5320),\n",
    "    \"mu2\": (5240,5320),\n",
    "    \"sigma1\": (40, 50),\n",
    "    \"sigma2\": (50, 40),\n",
    "    \"A\": (-0.1, 0.1),\n",
    "    \"b\": (-1, 1),\n",
    "}\n",
    "\n",
    "variables[\"random_search\" + root_name] = RandomSearch(variables[\"bins\" + root_name], variables[\"nC\" + root_name], fit_class=DoubleGaussian_plus_Exp, search_ranges=variables[\"param_ranges\" + root_name], num_searches=100)\n",
    "\n",
    "# Perform the search\n",
    "variables[\"best_score\" + root_name], variables[\"best_params\" + root_name], variables[\"best_fit\" + root_name] = variables[\"random_search\" + root_name].perform_search()\n",
    "\n",
    "# Print the results\n",
    "print(\"Best chi2:\", variables[\"best_score\" + root_name])\n",
    "print(\"Best initial parameters:\", variables[\"best_params\" + root_name])\n",
    "\n",
    "# Fit the best_fit with the best_params\n",
    "best_params_list = [variables[\"best_params\" + root_name][param] for param in [\"n_s\", \"f\", \"n_b\", \"mu1\", \"mu2\", \"sigma1\", \"sigma2\", \"A\", \"b\"]]\n",
    "variables[\"best_fit_m\" + root_name] = variables[\"best_fit\" + root_name].fit(best_params_list)\n",
    "\n",
    "\n",
    "# Print the fitted parameters in a nice format to copy-paste\n",
    "variables[\"parsed_output\" + root_name] = parse_best_fit_parameters(variables[\"best_fit_m\" + root_name].values)\n",
    "print(variables[\"parsed_output\" + root_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm intetested into `Bu_IPCHI2_OWNPV` so lets plot it with sidebands around `B_region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the B region and sidebands\n",
    "B_region = (5255, 5305)\n",
    "left_sideband = (B_region[0] - 100, B_region[0])\n",
    "right_sideband = (B_region[1], B_region[1] + 100)\n",
    "\n",
    "# Apply the Bu_IPCHI2_OWNPV cut\n",
    "Bu_IPChi = Bu_MM[Bu_IPCHI2_OWNPV < 10]\n",
    "\n",
    "# Plot the B region and sidebands\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "axs[0].hist(Bu_IPChi[(Bu_IPChi > B_region[0]) & (Bu_IPChi < B_region[1])], bins=50)\n",
    "axs[0].set_xlabel('B+ mass [MeV]')\n",
    "axs[0].set_ylabel('Entries')\n",
    "axs[0].set_title('B region with Bu_IPCHI2_OWNPV < 10')\n",
    "\n",
    "axs[1].hist(Bu_IPChi[(Bu_IPChi > left_sideband[0]) & (Bu_IPChi < left_sideband[1])], bins=50)\n",
    "axs[1].set_xlabel('B+ mass [MeV]')\n",
    "axs[1].set_title('Left sideband')\n",
    "\n",
    "axs[2].hist(Bu_IPChi[(Bu_IPChi > right_sideband[0]) & (Bu_IPChi < right_sideband[1])], bins=50)\n",
    "axs[2].set_xlabel('B+ mass [MeV]')\n",
    "axs[2].set_title('Right sideband')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what about `good_b`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the B region and sidebands\n",
    "B_region = (5255, 5305)\n",
    "left_sideband = (B_region[0] - 100, B_region[0])\n",
    "right_sideband = (B_region[1], B_region[1] + 100)\n",
    "\n",
    "good_cut = Bu_MM[good_b]\n",
    "# Plot the B region and sidebands\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "axs[0].hist(good_cut[(good_cut > B_region[0]) & (good_cut < B_region[1])], bins=50)\n",
    "axs[0].set_xlabel('B+ mass [MeV]')\n",
    "axs[0].set_ylabel('Entries')\n",
    "axs[0].set_title('B region with good_b')\n",
    "\n",
    "axs[1].hist(good_cut[(good_cut > left_sideband[0]) & (good_cut < left_sideband[1])], bins=50)\n",
    "axs[1].set_xlabel('B+ mass [MeV]')\n",
    "axs[1].set_title('Left sideband')\n",
    "\n",
    "axs[2].hist(good_cut[(good_cut > right_sideband[0]) & (good_cut < right_sideband[1])], bins=50)\n",
    "axs[2].set_xlabel('B+ mass [MeV]')\n",
    "axs[2].set_title('Right sideband')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1_4vec  = vector.awk({\"x\":h1_PX, \"y\":h1_PY, \"z\":h1_PZ, \"t\":h1_PE}) # K+ rd\n",
    "K2_4vec  = vector.awk({\"x\":h2_PX, \"y\":h2_PY, \"z\":h2_PZ, \"t\":h2_PE}) # K+ rd \n",
    "p_4vec   = vector.awk({\"x\":p_PX,  \"y\":p_PY,  \"z\":p_PZ,  \"t\":p_PE}) # p rd \n",
    "L0_4vec  = vector.awk({\"x\":L0_PX,  \"y\":L0_PY,  \"z\":L0_PZ,  \"t\":L0_PE}) # L0 rd \n",
    "\n",
    "K1_4vec_mc = vector.awk({\"x\":h1_PX_mc, \"y\":h1_PY_mc, \"z\":h1_PZ_mc, \"t\":h1_PE_mc}) # K+ mc\n",
    "K2_4vec_mc = vector.awk({\"x\":h2_PX_mc, \"y\":h2_PY_mc, \"z\":h2_PZ_mc, \"t\":h2_PE_mc}) # K+ mc\n",
    "p_4vec_mc  = vector.awk({\"x\":p_PX_mc,  \"y\":p_PY_mc,  \"z\":p_PZ_mc,  \"t\":p_PE_mc}) # p mc\n",
    "L0_4vec_mc = vector.awk({\"x\":L0_PX_mc,  \"y\":L0_PY_mc,  \"z\":L0_PZ_mc,  \"t\":L0_PE_mc}) # L0 mc\n",
    "\n",
    "KK_4vec  = K1_4vec+K2_4vec\n",
    "KK_mass  = KK_4vec.tau\n",
    "KK_4vec_mc  = K1_4vec_mc+K2_4vec_mc\n",
    "KK_mass_mc  = KK_4vec_mc.tau\n",
    "pKK_4vec = p_4vec+KK_4vec \n",
    "pKK_4vec_mc = p_4vec_mc+KK_4vec_mc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Create a figure with 1 row and 2 columns of subplots\n",
    "\n",
    "# Real data plot\n",
    "axs[0].hist(KK_mass[good_b], bins=100, range=(900, 3000))\n",
    "axs[0].set_title(\"Invariant mass of K+ K+ (Real Data)\")\n",
    "axs[0].set_xlabel(\"K+ K+ Invariant mass\")\n",
    "axs[0].set_ylabel(\"Entries per 31 MeV\")\n",
    "\n",
    "# MC data plot\n",
    "axs[1].hist(KK_mass_mc, bins=100, range=(900, 3000))  # Assuming good_b_mc for MC data\n",
    "axs[1].set_title(\"Invariant mass of K+ K+ (MC Data)\")\n",
    "axs[1].set_xlabel(\"K+ K+ Invariant mass\")\n",
    "axs[1].set_ylabel(\"Entries per 31 MeV\")\n",
    "\n",
    "plt.tight_layout()  # To ensure proper spacing between plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Λ p K⁺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets add the Λ₋pK₁⁺ system and define a four momentum for it (First K+)\n",
    "LbarpKp1_4vec = L0_4vec + p_4vec + K1_4vec\n",
    "LbarpKp1_mass = np.sqrt(np.square(LbarpKp1_4vec.t) - np.square(LbarpKp1_4vec.x) - np.square(LbarpKp1_4vec.y) - np.square(LbarpKp1_4vec.z))\n",
    "\n",
    "\n",
    "LbarpKp1_4vec_mc = L0_4vec_mc + p_4vec_mc + K1_4vec_mc\n",
    "LbarpKp1_mass_mc = np.sqrt(np.square(LbarpKp1_4vec_mc.t) - np.square(LbarpKp1_4vec_mc.x) - np.square(LbarpKp1_4vec_mc.y) - np.square(LbarpKp1_4vec_mc.z))\n",
    "\n",
    "# Now lets add the Λ₋pK₂⁺ system and define a four momentum for it (Second K+)\n",
    "LbarpKp2_4vec = L0_4vec + p_4vec + K2_4vec\n",
    "LbarpKp2_4vec_mc = L0_4vec_mc + p_4vec_mc + K2_4vec_mc\n",
    "LbarpKp2_mass = np.sqrt(np.square(LbarpKp2_4vec.t) - np.square(LbarpKp2_4vec.x) - np.square(LbarpKp2_4vec.y) - np.square(LbarpKp2_4vec.z))\n",
    "LbarpKp2_mass_mc = np.sqrt(np.square(LbarpKp2_4vec_mc.t) - np.square(LbarpKp2_4vec_mc.x) - np.square(LbarpKp2_4vec_mc.y) - np.square(LbarpKp2_4vec_mc.z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Create a figure with 1 row and 2 columns of subplots\n",
    "\n",
    "# Real data plot\n",
    "axs[0].hist(LbarpKp1_mass[good_b], bins=100)\n",
    "axs[0].set_title(r\"Invariant mass of $\\Lambda$̄  p K+ (First K+ - Real Data)\")\n",
    "axs[0].set_xlabel(r\" $\\Lambda$ p K+ Invariant mass\")\n",
    "axs[0].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "# MC data plot\n",
    "axs[1].hist(LbarpKp1_mass_mc, bins=100)  # Assuming good_b_mc for MC data\n",
    "axs[1].set_title(r\"Invariant mass of $\\Lambda$̄  p K+ (First K+ - MC Data)\")\n",
    "axs[1].set_xlabel(r\" $\\Lambda$ p K+ Invariant mass\")\n",
    "axs[1].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "plt.tight_layout()  # To ensure proper spacing between plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Create a figure with 1 row and 2 columns of subplots\n",
    "\n",
    "# Real data plot\n",
    "axs[0].hist(LbarpKp2_mass[good_b], bins=100)\n",
    "axs[0].set_title(r\"Invariant mass of $\\Lambda$̄  p K+ (Second K+ - Real Data)\")\n",
    "axs[0].set_xlabel(r\" $\\Lambda$ p K+ Invariant mass\")\n",
    "axs[0].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "# MC data plot\n",
    "axs[1].hist(LbarpKp2_mass_mc, bins=100)  # Assuming good_b_mc for MC data\n",
    "axs[1].set_title(r\"Invariant mass of $\\Lambda$̄  p K+ (Second K+ - MC Data)\")\n",
    "axs[1].set_xlabel(r\" $\\Lambda$ p K+ Invariant mass\")\n",
    "axs[1].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "plt.tight_layout()  # To ensure proper spacing between plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K^{+} K^{+}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Create a figure with 1 row and 2 columns of subplots\n",
    "\n",
    "# Real data plot\n",
    "axs[0].hist(KK_mass[good_b], bins=100)\n",
    "axs[0].set_title(r\"Invariant mass of K+ K+ (Real Data)\")\n",
    "axs[0].set_xlabel(r\" K+K+ Invariant mass\")\n",
    "axs[0].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "# MC data plot\n",
    "axs[1].hist(KK_mass_mc, bins=100)  # Assuming good_b_mc for MC data\n",
    "axs[1].set_title(r\"Invariant mass of K+ K+  (MC Data)\")\n",
    "axs[1].set_xlabel(r\" K+ K+ Invariant mass\")\n",
    "axs[1].set_ylabel(\"Entries per 10 MeV\")\n",
    "\n",
    "plt.tight_layout()  # To ensure proper spacing between plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bphysics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
